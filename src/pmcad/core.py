from typing import List, Union, Dict
import pandas as pd
from ._core import read_multi_tsv
from ._core import find_files as _find_files
from ._core import match_reference as _match_reference
from ._core import insert_files_to_pgdb as _insert_files_to_pgdb
from ._core import UniprotImporter
import os
import subprocess
import time
import json
import signal
import gzip


def read_tsv_files(filelist: List[str]) -> pd.DataFrame:
    """Read multiple TSV files and return a single DataFrame"""
    # è°ƒç”¨ read_multi_tsv è¯»å–æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®
    data = read_multi_tsv(filelist)  # å‡è®¾è¿”å›çš„æ˜¯ä¸€ä¸ªåˆå¹¶åçš„æ•°æ®åˆ—è¡¨

    # å¦‚æœæ•°æ®éç©ºï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
    if data:
        columns = data[0]  # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯åˆ—å
        return pd.DataFrame(data[1:], columns=columns)  # è¿”å›åˆå¹¶åçš„ DataFrame
    else:
        return pd.DataFrame()  # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ä¸€ä¸ªç©º DataFrame


def create_dict(
    x: List[str], y: List[str], splitx_by: Union[List[str], str] = []
) -> dict:
    """
    åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°† x ä¸­çš„æ¯ä¸ªå…ƒç´ æ˜ å°„åˆ° y ä¸­çš„ç›¸åº”å…ƒç´ ï¼Œ
    å¦‚æœ splitx_by ä¸­æä¾›äº†åˆ†éš”ç¬¦ï¼Œä¼šå°† x ä¸­çš„å…ƒç´ æŒ‰è¿™äº›åˆ†éš”ç¬¦æ‹†åˆ†ï¼Œæ‹†åˆ†åçš„å­å…ƒç´ å»é™¤å‰åç©ºæ ¼åä¹Ÿæ˜ å°„åˆ°ç›¸åŒçš„ y å…ƒç´ ã€‚

    å‚æ•°:
        x (List[str]): ç”¨ä½œå­—å…¸é”®çš„åˆ—è¡¨
        y (List[str]): ç”¨ä½œå­—å…¸å€¼çš„åˆ—è¡¨
        splitx_by (Optional[Union[List[str], str]], optional):
            ç”¨äºæ‹†åˆ† x ä¸­æ¯ä¸ªå…ƒç´ çš„åˆ†éš”ç¬¦ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ï¼ˆå•ä¸€åˆ†éš”ç¬¦ï¼‰æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå¤šä¸ªåˆ†éš”ç¬¦ï¼‰ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨

    è¿”å›:
        dict: æ˜ å°„åçš„å­—å…¸
    """

    # å¤„ç† splitx_by ç±»å‹ä¸ºåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
    if isinstance(splitx_by, str):  # å¦‚æœæ˜¯å•ä¸ªåˆ†éš”ç¬¦
        splitx_by = [splitx_by]

    result_dict = {}

    # éå† x å’Œ yï¼Œå‡è®¾ x å’Œ y é•¿åº¦ä¸€è‡´
    for xi, yi in zip(x, y):
        if not isinstance(xi, str):  # æ£€æŸ¥ xi æ˜¯å¦ä¸ºå­—ç¬¦ä¸²
            xi = str(xi)
        if xi == "nan":
            continue
        # å¦‚æœæŒ‡å®šäº†åˆ†éš”ç¬¦ï¼Œåˆ™æ‹†åˆ† x ä¸­çš„å…ƒç´ 
        if splitx_by:
            for delimiter in splitx_by:
                xi_split = xi.split(delimiter)  # æŒ‰æŒ‡å®šåˆ†éš”ç¬¦æ‹†åˆ†
                for sub_x in xi_split:
                    sub_x = sub_x.strip().lower()  # å»é™¤å‰åç©ºæ ¼å¹¶è½¬ä¸ºå°å†™
                    if sub_x in result_dict:
                        result_dict[sub_x].append(
                            yi
                        )  # å¦‚æœå·²ç»å­˜åœ¨ï¼Œæ·»åŠ åˆ°ç°æœ‰çš„åˆ—è¡¨ä¸­
                    else:
                        result_dict[sub_x] = [yi]  # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„æ˜ å°„
        else:
            xi = xi.strip().lower()  # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œç›´æ¥å°†å…ƒç´ æ˜ å°„ï¼Œå¹¶å»é™¤å‰åç©ºæ ¼
            if xi in result_dict:
                result_dict[xi].append(yi)
            else:
                result_dict[xi] = [yi]

    return result_dict


def match_reference(
    query: List[str], reference: Dict[str, List[str]], verbose: bool = False
) -> Dict[str, List[str]]:
    return _match_reference(query, reference, verbose)


def find_files(foldername: str, pattern: str) -> List[str]:
    """
    åœ¨æŒ‡å®šæ–‡ä»¶å¤¹åŠå…¶å­æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…ç»™å®šæ­£åˆ™è¡¨è¾¾å¼çš„æ–‡ä»¶ã€‚

    å‚æ•°:
        foldername (str): è¦æœç´¢çš„æ ¹æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        pattern (str): ç”¨äºåŒ¹é…æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚

    è¿”å›:
        List[str]: è¿”å›åŒ¹é…æ–‡ä»¶çš„å®Œæ•´è·¯å¾„åˆ—è¡¨ã€‚

    ç¤ºä¾‹:
        >>> find_files("/home/user/data", r"^final_file_\d+\.tsv$")
        ['/home/user/data/final_file_1.tsv', '/home/user/data/final_file_2.tsv']
    """
    return _find_files(foldername, pattern)


def insert_files_to_pgdb(
    filelist: List[str], table_name: str, dbpath: str, verbose: bool = False
):
    """
    å°†æ–‡ä»¶åˆ—è¡¨æ’å…¥ PostgreSQL æ•°æ®åº“è¡¨ä¸­ï¼Œç›´æ¥é€šè¿‡ dbpath è‡ªåŠ¨è·å–è¿æ¥ä¿¡æ¯ã€‚

    å‚æ•°:
        filelist (List[str]): æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        table_name (str): æ•°æ®åº“è¡¨å
        dbpath (str): æ•°æ®åº“è·¯å¾„ï¼ŒåŒ…å« database.info
        verbose (bool): æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    dbname = db_info["dbname"]
    user = db_info["user"]
    password = db_info["password"]
    host = db_info.get("host", "localhost")
    port = str(db_info.get("port", 5432))

    _insert_files_to_pgdb(
        filelist=filelist,
        table_name=table_name,
        dbname=dbname,
        user=user,
        password=password,
        host=host,
        port=port,
        verbose=verbose,
    )


def init_pgdb(
    dbpath,
    pgbinpath,
    admin_user="postgres",
    admin_password="postgres",
    host="localhost",
    port=5432,
    wait_seconds=2,
):
    """
    åˆå§‹åŒ– PostgreSQL æ•°æ®åº“å¹¶åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·ï¼ˆå¯é€‰é»˜è®¤è´¦å·å¯†ç ï¼‰

    å‚æ•°:
        dbpath (str): æ•°æ®åº“å­˜æ”¾ç›®å½•ï¼Œä¼šåœ¨æ­¤ç›®å½•ä¸‹ç”Ÿæˆ data/
        pgbinpath (str): PostgreSQL å¯æ‰§è¡Œç¨‹åºç›®å½•ï¼Œå¿…é¡»åŒ…å« initdbã€pg_ctlã€psql
        admin_user (str): ç®¡ç†å‘˜ç”¨æˆ·åï¼ˆé»˜è®¤ "postgres"ï¼‰
        admin_password (str): ç®¡ç†å‘˜å¯†ç ï¼ˆé»˜è®¤ "postgres"ï¼‰
        host (str): æ•°æ®åº“ä¸»æœºï¼ˆé»˜è®¤ "localhost"ï¼‰
        port (int): PostgreSQL æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ 5432ï¼‰
        wait_seconds (float): å¯åŠ¨æ•°æ®åº“åçš„ç­‰å¾…æ—¶é—´ï¼Œä¿è¯æ•°æ®åº“å¯è¿æ¥

    è¿”å›:
        dict: æ•°æ®åº“è¿æ¥ä¿¡æ¯
    """

    os.makedirs(dbpath, exist_ok=True)
    data_dir = os.path.join(dbpath, "data")
    os.makedirs(data_dir, exist_ok=True)

    initdb_path = os.path.join(pgbinpath, "initdb")
    pg_ctl_path = os.path.join(pgbinpath, "pg_ctl")
    psql_path = os.path.join(pgbinpath, "psql")
    dbname = "postgres"

    # 1ï¸âƒ£ åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ PG_VERSIONï¼‰
    if not os.path.exists(os.path.join(data_dir, "PG_VERSION")):
        subprocess.run(
            [initdb_path, "-D", data_dir, "--username", admin_user], check=True
        )
        print(
            f"Initialized PostgreSQL data directory at {data_dir} with admin user '{admin_user}'"
        )

    # 2ï¸âƒ£ å¯åŠ¨æ•°æ®åº“
    subprocess.run(
        [
            pg_ctl_path,
            "-D",
            data_dir,
            "-o",
            f"-p {port}",
            "-l",
            os.path.join(data_dir, "logfile"),
            "start",
        ],
        check=True,
    )
    print("PostgreSQL server starting...")
    time.sleep(wait_seconds)

    # 3ï¸âƒ£ è®¾ç½®ç®¡ç†å‘˜å¯†ç 
    set_password_sql = f"ALTER USER {admin_user} WITH PASSWORD '{admin_password}';"
    subprocess.run(
        [
            psql_path,
            "-U",
            admin_user,
            "-p",
            str(port),
            "-d",
            dbname,
            "-c",
            set_password_sql,
        ],
        check=True,
        env={**os.environ, "PGPASSWORD": ""},
    )

    print(f"Admin user '{admin_user}' ready on port {port}")

    # 4ï¸âƒ£ ä¿å­˜è¿æ¥ä¿¡æ¯åˆ° dbpath/database.info
    db_info = {
        "pgbinpath": pgbinpath,
        "dbname": dbname,
        "user": admin_user,
        "password": admin_password,
        "host": host,
        "port": port,
        "data_dir": data_dir,
    }
    info_path = os.path.join(dbpath, "database.info")
    with open(info_path, "w") as f:
        json.dump(db_info, f, indent=2)
    print(f"Database connection info saved to {info_path}")

    return db_info


def remove_pgdb(dbpath):
    """
    æ ¹æ® dbpath/database.info åˆ é™¤æ•°æ®åº“æ–‡ä»¶ï¼Œå¹¶é‡Šæ”¾ç«¯å£ã€‚
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        print(f"No database.info found at {info_file}")
        return

    # è¯»å–ç«¯å£ä¿¡æ¯
    with open(info_file, "r") as f:
        db_info = json.load(f)
    port = db_info.get("port", 5432)

    # æ€æ‰å ç”¨ç«¯å£çš„ postgres è¿›ç¨‹
    try:
        result = subprocess.run(
            ["lsof", "-ti", f":{port}"], capture_output=True, text=True
        )
        pids = result.stdout.strip().split("\n")
        for pid in pids:
            if pid:
                print(f"Killing process {pid} on port {port}")
                os.kill(int(pid), signal.SIGTERM)
    except Exception as e:
        print(f"Failed to kill processes on port {port}: {e}")

    # åˆ é™¤æ•°æ®åº“ç›®å½•
    data_dir = db_info.get("data_dir", os.path.join(dbpath, "data"))
    if os.path.exists(data_dir):
        for root, dirs, files in os.walk(data_dir, topdown=False):
            for name in files:
                os.remove(os.path.join(root, name))
            for name in dirs:
                os.rmdir(os.path.join(root, name))
        os.rmdir(data_dir)
        print(f"Deleted data directory: {data_dir}")

    # åˆ é™¤ database.info æ–‡ä»¶
    os.remove(info_file)
    print(f"Deleted database info file: {info_file}")

    print(f"Database at {dbpath} removed and port {port} freed.")


def pg_exec(dbpath, sql=None, interactive=False):
    """
    åœ¨ Python ä¸­è°ƒç”¨ PostgreSQL å‘½ä»¤è¡Œå·¥å…· (psql)
    å¯ä»¥æ‰§è¡Œ SQL å‘½ä»¤æˆ–è¿›å…¥äº¤äº’æ¨¡å¼ã€‚

    å‚æ•°:
        dbpath (str): åŒ…å« database.info çš„æ•°æ®åº“è·¯å¾„
        sql (str): è¦æ‰§è¡Œçš„ SQL å‘½ä»¤ï¼ˆå¦‚ "SELECT * FROM table;"ï¼‰ï¼Œå¯é€‰
        interactive (bool): è‹¥ä¸º Trueï¼Œåˆ™è¿›å…¥äº¤äº’å¼ psql shell

    è¿”å›:
        str: SQL å‘½ä»¤è¾“å‡ºç»“æœï¼ˆè‹¥éäº¤äº’æ¨¡å¼ï¼‰
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    # è¯»å–è¿æ¥ä¿¡æ¯
    with open(info_file, "r") as f:
        db_info = json.load(f)

    psql_path = os.path.join(db_info["pgbinpath"], "psql")

    env = {**os.environ, "PGPASSWORD": db_info["password"]}

    cmd = [
        psql_path,
        "-U",
        db_info["user"],
        "-d",
        db_info["dbname"],
        "-h",
        db_info["host"],
        "-p",
        str(db_info["port"]),
    ]

    # è‹¥ interactive=Trueï¼Œåˆ™ç›´æ¥è¿›å…¥ psql ç»ˆç«¯
    if interactive:
        print(f"Connecting to PostgreSQL at port {db_info['port']}...\n")
        subprocess.run(cmd, env=env)
        return

    # è‹¥ç»™å®š SQLï¼Œåˆ™æ‰§è¡Œå¹¶è¿”å›ç»“æœ
    if sql:
        cmd += ["-c", sql]
        result = subprocess.run(cmd, capture_output=True, text=True, env=env)
        if result.returncode != 0:
            raise RuntimeError(f"SQL execution failed:\n{result.stderr}")
        return result.stdout.strip()

    raise ValueError("Must provide either sql command or set interactive=True")


def import_gz_table(dbpath, gz_file, table_name, header=None, pvpath=None):
    """
    å°† gzip å‹ç¼©çš„è¡¨æ ¼æ–‡ä»¶å¯¼å…¥ PostgreSQL æ•°æ®åº“ï¼Œå¹¶æ˜¾ç¤ºå­—èŠ‚è¿›åº¦ã€‚

    è‡ªåŠ¨è¯»å–è¡¨å¤´ã€è‡ªåŠ¨å»ºè¡¨ï¼ˆtext ç±»å‹ï¼‰ã€å»æ‰ # å­—ç¬¦ã€‚

    å‚æ•°:
        dbpath (str): åŒ…å« database.info çš„æ•°æ®åº“è·¯å¾„
        gz_file (str): è¦å¯¼å…¥çš„ .gz æ–‡ä»¶è·¯å¾„
        table_name (str): PostgreSQL ä¸­ç›®æ ‡è¡¨å
        pvpath (str): pv å‘½ä»¤è·¯å¾„ï¼Œé»˜è®¤ None

    è¿”å›:
        None
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    # è¯»å–æ•°æ®åº“è¿æ¥ä¿¡æ¯
    with open(info_file, "r") as f:
        db_info = json.load(f)

    psql_path = os.path.join(db_info["pgbinpath"], "psql")
    env = {**os.environ, "PGPASSWORD": db_info["password"]}

    # è¯»å–è¡¨å¤´ï¼Œè‡ªåŠ¨è¯†åˆ«åˆ†éš”ç¬¦
    with gzip.open(gz_file, "rt") as f:
        first_line = f.readline().strip()
        if "\t" in first_line:
            delimiter = "\t"
        elif "," in first_line:
            delimiter = ","
        else:
            delimiter = "\t"  # é»˜è®¤
        columns = [col.strip().lstrip("#") for col in first_line.split(delimiter)]

    if header is not None:
        columns = list(header)
        skip_cmd = "cat"
    else:
        skip_cmd = "tail -n +2"
        
    # ç”Ÿæˆå»ºè¡¨ SQLï¼ˆæ‰€æœ‰åˆ— text ç±»å‹ï¼‰
    col_defs = ",\n  ".join([f'"{col}" text' for col in columns])
    create_sql = f"CREATE TABLE IF NOT EXISTS {table_name} (\n  {col_defs}\n);"

    print(f"Creating table {table_name} if not exists...")
    subprocess.run(
        [
            psql_path,
            "-U",
            db_info["user"],
            "-d",
            db_info["dbname"],
            "-h",
            db_info["host"],
            "-p",
            str(db_info["port"]),
            "-c",
            create_sql,
        ],
        env=env,
        check=True,
    )

    # æ„é€  \copy å‘½ä»¤
    copy_cmd = (
        f"\\copy {table_name} FROM STDIN WITH (FORMAT text, DELIMITER E'{delimiter}')"
    )

    # ä½¿ç”¨ pv + gunzip å¯¼å…¥
    # full_cmd = f"gunzip | sed 's/\\\\//g' | {psql_path} -U {db_info['user']} -d {db_info['dbname']} -h {db_info['host']} -p {db_info['port']} -c \"{copy_cmd}\""

    if pvpath:
        full_cmd = (
            f"{pvpath} {gz_file} | gunzip | {skip_cmd} | sed 's/\\\\//g' | "
            f"{psql_path} -U {db_info['user']} -d {db_info['dbname']} "
            f"-h {db_info['host']} -p {db_info['port']} -c \"{copy_cmd}\""
        )
    else:
        full_cmd = (
            f"gunzip -c {gz_file} | {skip_cmd} | sed 's/\\\\//g' | "
            f"{psql_path} -U {db_info['user']} -d {db_info['dbname']} "
            f"-h {db_info['host']} -p {db_info['port']} -c \"{copy_cmd}\""
        )

    print(f"Importing {gz_file} into table {table_name} with progress bar...\n")
    result = subprocess.run(full_cmd, shell=True, env=env)
    if result.returncode != 0:
        raise RuntimeError(f"Import failed for {gz_file}")
    print("Import completed successfully.")

def pg_start(dbpath):
    """
    å¯åŠ¨ PostgreSQL æ•°æ®åº“å®ä¾‹ï¼ˆæç®€åå°ç‰ˆï¼Œå¯åŠ¨å‰åˆ¤æ–­æ˜¯å¦å·²è¿è¡Œï¼‰
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    pgbin = db_info.get("pgbinpath")
    datadir = db_info.get("data_dir")
    port = str(db_info.get("port", 5432))

    if not pgbin or not datadir:
        raise ValueError("database.info å¿…é¡»åŒ…å« pgbinpath å’Œ data_dir å­—æ®µ")

    pg_ctl = os.path.join(pgbin, "pg_ctl")
    logfile = os.path.join(dbpath, "pg.log")

    # === 1. æ£€æŸ¥æ˜¯å¦å·²å¯åŠ¨ ===
    status_cmd = [pg_ctl, "status", "-D", datadir]
    status = subprocess.run(status_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    if "server is running" in status.stdout:
        print("âœ… PostgreSQL å·²åœ¨è¿è¡Œï¼Œè·³è¿‡å¯åŠ¨ã€‚")
        return

    # === 2. æ„é€ å¯åŠ¨å‘½ä»¤ ===
    cmd = [
        pg_ctl,
        "-D", datadir,
        "-l", logfile,
        "-o", f"-p {port}",
        "start"
    ]

    # print(" ".join(cmd))

    # === 3. åå°å¯åŠ¨ ===
    subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print("ğŸš€ PostgreSQL å¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼ˆåå°è¿è¡Œä¸­ï¼‰")

def pg_stop(dbpath):
    """
    å…³é—­ PostgreSQL æ•°æ®åº“å®ä¾‹ï¼ˆæç®€åå°ç‰ˆï¼Œå…³é—­å‰åˆ¤æ–­æ˜¯å¦å·²è¿è¡Œï¼‰
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    pgbin = db_info.get("pgbinpath")
    datadir = db_info.get("data_dir")

    if not pgbin or not datadir:
        raise ValueError("database.info å¿…é¡»åŒ…å« pgbinpath å’Œ data_dir å­—æ®µ")

    pg_ctl = os.path.join(pgbin, "pg_ctl")

    # === 1. æ£€æŸ¥æ˜¯å¦å·²å¯åŠ¨ ===
    status_cmd = [pg_ctl, "status", "-D", datadir]
    status = subprocess.run(status_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    if "server is running" not in status.stdout:
        print("âšª PostgreSQL å½“å‰æœªè¿è¡Œï¼Œè·³è¿‡å…³é—­ã€‚")
        return

    # === 2. æ„é€ å…³é—­å‘½ä»¤ ===
    cmd = [
        pg_ctl,
        "-D", datadir,
        "stop"
    ]

    print(" ".join(cmd))

    # === 3. åå°å…³é—­ ===
    subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print("ğŸ›‘ PostgreSQL å…³é—­å‘½ä»¤å·²æ‰§è¡Œï¼ˆåå°è¿è¡Œä¸­ï¼‰")
    
def import_uniprot_ft(
    dbpath: str,
    gz_path: str,
    table_name: str = "uniprot_features",
    batch_commit: int = 200000,
    verbose: bool = True,
):
    """
    ä» UniProt .dat.gz æ–‡ä»¶ä¸­è§£æ Feature Table (FT) åŒºåŸŸå¹¶å¯¼å…¥ PostgreSQLã€‚
    ï¼ˆåŸºäº C++ é«˜é€Ÿè§£æä¸ COPY æ¨¡å¼ï¼Œæ”¯æŒè¾¹è§£å‹è¾¹å¯¼å…¥ï¼‰

    å‚æ•°:
        dbpath (str): åŒ…å« database.info çš„æ•°æ®åº“ç›®å½•ã€‚
        gz_path (str): UniProt .dat.gz æ–‡ä»¶è·¯å¾„ã€‚
        table_name (str): å¯¼å…¥çš„ç›®æ ‡è¡¨åï¼Œé»˜è®¤ä¸º "uniprot_features"ã€‚
        batch_commit (int): æ¯æ¬¡æäº¤äº‹åŠ¡çš„è®°å½•æ•°ï¼ˆé»˜è®¤ 200,000ï¼‰ã€‚
        verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆé»˜è®¤ Trueï¼‰ã€‚

    è¿”å›:
        None
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    dbname = db_info["dbname"]
    user = db_info["user"]
    password = db_info["password"]
    host = db_info.get("host", "localhost")
    port = str(db_info.get("port", 5432))

    print(f"\nğŸš€ Importing UniProt FT features into PostgreSQL table '{table_name}' ...\n")
    start = time.time()

    UniprotImporter.ft_stream_parse_and_copy(
        gz_path=gz_path,
        table_name=table_name,
        dbname=dbname,
        user=user,
        password=password,
        host=host,
        port=port,
        batch_commit=batch_commit,
        verbose=verbose,
    )

    print(f"\nâœ… Import finished in {time.time() - start:.2f} seconds.")
    
            
def import_uniprot_dr(
    dbpath: str,
    gz_path: str,
    table_name: str = "uniprot_features",
    batch_commit: int = 200000,
    verbose: bool = True,
):
    """
    ä» UniProt .dat.gz æ–‡ä»¶ä¸­è§£æ Feature Table (FT) åŒºåŸŸå¹¶å¯¼å…¥ PostgreSQLã€‚
    ï¼ˆåŸºäº C++ é«˜é€Ÿè§£æä¸ COPY æ¨¡å¼ï¼Œæ”¯æŒè¾¹è§£å‹è¾¹å¯¼å…¥ï¼‰

    å‚æ•°:
        dbpath (str): åŒ…å« database.info çš„æ•°æ®åº“ç›®å½•ã€‚
        gz_path (str): UniProt .dat.gz æ–‡ä»¶è·¯å¾„ã€‚
        table_name (str): å¯¼å…¥çš„ç›®æ ‡è¡¨åï¼Œé»˜è®¤ä¸º "uniprot_features"ã€‚
        batch_commit (int): æ¯æ¬¡æäº¤äº‹åŠ¡çš„è®°å½•æ•°ï¼ˆé»˜è®¤ 200,000ï¼‰ã€‚
        verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆé»˜è®¤ Trueï¼‰ã€‚

    è¿”å›:
        None
    """
    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    dbname = db_info["dbname"]
    user = db_info["user"]
    password = db_info["password"]
    host = db_info.get("host", "localhost")
    port = str(db_info.get("port", 5432))

    print(f"\nğŸš€ Importing UniProt dr features into PostgreSQL table '{table_name}' ...\n")
    start = time.time()

    UniprotImporter.dr_stream_parse_and_copy(
        gz_path=gz_path,
        table_name=table_name,
        dbname=dbname,
        user=user,
        password=password,
        host=host,
        port=port,
        batch_commit=batch_commit,
        verbose=verbose,
    )

    print(f"\nâœ… Import finished in {time.time() - start:.2f} seconds.")
    
def import_uniprot_sq(
    dbpath: str,
    gz_path: str,
    table_name: str = "uniprot_sequences",
    batch_commit: int = 20000,
    verbose: bool = True,
):
    """
    ä» UniProt .dat.gz æ–‡ä»¶ä¸­è§£æ Sequence (SQ) åŒºåŸŸå¹¶å¯¼å…¥ PostgreSQLã€‚
    ï¼ˆåŸºäº C++ é«˜é€Ÿè§£æä¸ COPY æ¨¡å¼ï¼Œæ”¯æŒè¾¹è§£å‹è¾¹å¯¼å…¥ï¼‰

    å‚æ•°:
        dbpath (str): åŒ…å« database.info çš„æ•°æ®åº“ç›®å½•ã€‚
        gz_path (str): UniProt .dat.gz æ–‡ä»¶è·¯å¾„ã€‚
        table_name (str): å¯¼å…¥çš„ç›®æ ‡è¡¨åï¼Œé»˜è®¤ä¸º "uniprot_sequences"ã€‚
        batch_commit (int): æ¯æ¬¡æäº¤äº‹åŠ¡çš„è®°å½•æ•°ï¼ˆé»˜è®¤ 20,000ï¼‰ã€‚
        verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆé»˜è®¤ Trueï¼‰ã€‚

    è¿”å›:
        None
    """

    info_file = os.path.join(dbpath, "database.info")
    if not os.path.exists(info_file):
        raise FileNotFoundError(f"No database.info found at {info_file}")

    with open(info_file, "r") as f:
        db_info = json.load(f)

    dbname = db_info["dbname"]
    user = db_info["user"]
    password = db_info["password"]
    host = db_info.get("host", "localhost")
    port = str(db_info.get("port", 5432))

    print(f"\nğŸš€ Importing UniProt sequence records into PostgreSQL table '{table_name}' ...\n")
    start = time.time()

    UniprotImporter.sq_stream_parse_and_copy(
        gz_path=gz_path,
        table_name=table_name,
        dbname=dbname,
        user=user,
        password=password,
        host=host,
        port=port,
        batch_commit=batch_commit,
        verbose=verbose,
    )

    print(f"\nâœ… Import finished in {time.time() - start:.2f} seconds.")
